{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samira   (0, 42787)\t0.0756866790121593\n",
      "  (0, 17656)\t0.052107322261785244\n",
      "  (0, 34626)\t0.06296860692073819\n",
      "  (0, 50256)\t0.06508748560359351\n",
      "  (0, 14842)\t0.06232012004548747\n",
      "  (0, 45022)\t0.04576779456588032\n",
      "  (0, 33470)\t0.0614172967952831\n",
      "  (0, 17392)\t0.04773445123264238\n",
      "  (0, 48685)\t0.07562464385443352\n",
      "  (0, 21394)\t0.0640757987289428\n",
      "  (0, 55698)\t0.059454384807373285\n",
      "  (0, 50646)\t0.05362094721928437\n",
      "  (0, 39027)\t0.0351863503077323\n",
      "  (0, 15964)\t0.08019600540204529\n",
      "  (0, 6819)\t0.0361411763425358\n",
      "  (0, 2834)\t0.0701814508257512\n",
      "  (0, 2597)\t0.06790274670175973\n",
      "  (0, 5150)\t0.09232321746469292\n",
      "  (0, 52945)\t0.04207227627750221\n",
      "  (0, 50202)\t0.06719055677234913\n",
      "  (0, 12418)\t0.051005351330109035\n",
      "  (0, 54929)\t0.05796784822637559\n",
      "  (0, 51726)\t0.04115540088634516\n",
      "  (0, 5715)\t0.07189743497339073\n",
      "  (0, 7554)\t0.06770808453903296\n",
      "  :\t:\n",
      "  (0, 26518)\t0.10941718893359764\n",
      "  (0, 39035)\t0.06682284633846308\n",
      "  (0, 10082)\t0.11773020586257094\n",
      "  (0, 3010)\t0.13645449233016066\n",
      "  (0, 3651)\t0.08192974695696721\n",
      "  (0, 48789)\t0.07850075214334741\n",
      "  (0, 9717)\t0.09617842020612044\n",
      "  (0, 1401)\t0.056270643261007024\n",
      "  (0, 44487)\t0.08126574207010834\n",
      "  (0, 52825)\t0.07892527563540944\n",
      "  (0, 2792)\t0.06520454825443969\n",
      "  (0, 26754)\t0.1784213307417608\n",
      "  (0, 18837)\t0.06674060680035618\n",
      "  (0, 3154)\t0.07185009514769763\n",
      "  (0, 25756)\t0.052528424781344146\n",
      "  (0, 39609)\t0.04746727213844484\n",
      "  (0, 33445)\t0.06253700664024438\n",
      "  (0, 2302)\t0.09998757658873575\n",
      "  (0, 52827)\t0.13649099306630225\n",
      "  (0, 30183)\t0.11682565094745069\n",
      "  (0, 37671)\t0.09900053693056554\n",
      "  (0, 26755)\t0.28866659510354387\n",
      "  (0, 21565)\t0.6173798561119618\n",
      "  (0, 48826)\t0.07441002926865045\n",
      "  (0, 11663)\t0.07216482954966394\n",
      "ammir   (0, 12928)\t0.056762400238631654\n",
      "  (0, 32116)\t0.03687565397717484\n",
      "  (0, 51489)\t0.033624300397388555\n",
      "  (0, 47898)\t0.041458541285390095\n",
      "  (0, 46635)\t0.04377061104614689\n",
      "  (0, 45031)\t0.04235850057658584\n",
      "  (0, 42979)\t0.046869767596901396\n",
      "  (0, 10074)\t0.027956666093772568\n",
      "  (0, 36778)\t0.05376403462495488\n",
      "  (0, 16943)\t0.035649430831103945\n",
      "  (0, 5857)\t0.09414303063528752\n",
      "  (0, 26881)\t0.041485072504560454\n",
      "  (0, 30038)\t0.04980711977735876\n",
      "  (0, 44693)\t0.0368650258893204\n",
      "  (0, 14761)\t0.033168531980801906\n",
      "  (0, 45469)\t0.03187577704238961\n",
      "  (0, 2566)\t0.08326649246186708\n",
      "  (0, 16543)\t0.10038706605161757\n",
      "  (0, 32268)\t0.06520233180241991\n",
      "  (0, 959)\t0.09154414714590312\n",
      "  (0, 26567)\t0.02572315894858619\n",
      "  (0, 29802)\t0.02921747499463052\n",
      "  (0, 11197)\t0.046918120292001035\n",
      "  (0, 47663)\t0.03205173708913576\n",
      "  (0, 19262)\t0.046461209776425746\n",
      "  :\t:\n",
      "  (0, 18543)\t0.06372330561786724\n",
      "  (0, 12424)\t0.047031959990028856\n",
      "  (0, 26382)\t0.03252529213273018\n",
      "  (0, 31522)\t0.5053098362781907\n",
      "  (0, 53090)\t0.12240527594644404\n",
      "  (0, 15638)\t0.10104930893143838\n",
      "  (0, 27597)\t0.058623414717134295\n",
      "  (0, 22188)\t0.11249741665958281\n",
      "  (0, 37175)\t0.066070945043622\n",
      "  (0, 56538)\t0.0557476804300858\n",
      "  (0, 12983)\t0.08428925823658377\n",
      "  (0, 47363)\t0.16807359368324973\n",
      "  (0, 30962)\t0.12178751500940327\n",
      "  (0, 18153)\t0.15312784849002006\n",
      "  (0, 53088)\t0.12075479123386845\n",
      "  (0, 10781)\t0.13493075031998883\n",
      "  (0, 31678)\t0.10255582676859921\n",
      "  (0, 38834)\t0.15816904144673746\n",
      "  (0, 54665)\t0.11404907677846506\n",
      "  (0, 17656)\t0.03365030786566565\n",
      "  (0, 12418)\t0.03293866774484688\n",
      "  (0, 51726)\t0.026577683328319158\n",
      "  (0, 49356)\t0.038747761391447845\n",
      "  (0, 26518)\t0.03533017946032062\n",
      "  (0, 30183)\t0.037722329131002076\n",
      "train time: 0.041s\n",
      "test time:  0.014s\n",
      "accuracy:   0.355\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.27      0.32       899\n",
      "           2       0.50      0.06      0.11       442\n",
      "           3       0.59      0.06      0.11       167\n",
      "           4       0.47      0.70      0.56      2207\n",
      "           5       0.40      0.07      0.12       569\n",
      "           6       0.46      0.20      0.28       991\n",
      "           7       1.00      0.01      0.01       179\n",
      "           8       0.46      0.13      0.20       884\n",
      "           9       0.40      0.01      0.01       270\n",
      "          10       0.45      0.17      0.24      1368\n",
      "          11       0.48      0.16      0.24       367\n",
      "          12       0.51      0.15      0.23       876\n",
      "          13       0.49      0.19      0.27       604\n",
      "          14       0.54      0.69      0.60      2025\n",
      "          15       0.56      0.02      0.04       468\n",
      "          16       0.50      0.02      0.04       388\n",
      "          17       0.59      0.13      0.22       549\n",
      "          18       0.55      0.31      0.40       708\n",
      "          19       0.47      0.03      0.05       313\n",
      "          20       0.40      0.47      0.43      1102\n",
      "          21       0.62      0.17      0.26      1065\n",
      "          22       0.00      0.00      0.00       182\n",
      "          23       0.21      0.59      0.31      3322\n",
      "\n",
      "    accuracy                           0.36     19945\n",
      "   macro avg       0.48      0.20      0.22     19945\n",
      "weighted avg       0.44      0.36      0.32     19945\n",
      "\n",
      "Percision_micro-average:   0.36\n",
      "Percision_macro-average:   0.48\n",
      "Recall_micro-average:   0.36\n",
      "Recall_macro-average:   0.20\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\samiravz\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\samiravz\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\samiravz\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\samiravz\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "from time import time\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn import metrics,svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "target_names = ['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23']\n",
    "\n",
    "def get_files_in_dir(directory):\n",
    "    file_names_list = []\n",
    "    for file_name in glob.glob(directory):\n",
    "        file_names_list += [file_name]\n",
    "    return file_names_list\n",
    "\n",
    "\n",
    "def get_text_file_data(file):\n",
    "    data = []\n",
    "    with open(file, 'r', encoding=\"latin-1\") as file:\n",
    "      for line in file:\n",
    "        data += [str(line)]\n",
    "    return data\n",
    "\n",
    "\n",
    "def micro_macro_average(test_labels, test_pred):\n",
    "    print(\"Percision_micro-average:   %0.2f\" % precision_score(test_labels, test_pred, average='micro'))\n",
    "    print(\"Percision_macro-average:   %0.2f\" % precision_score(test_labels, test_pred, average='macro'))\n",
    "    print(\"Recall_micro-average:   %0.2f\" % recall_score(test_labels, test_pred, average='micro'))\n",
    "    print(\"Recall_macro-average:   %0.2f\" % recall_score(test_labels, test_pred, average='macro'))\n",
    "\n",
    "\n",
    "\n",
    "def test_training_data():\n",
    "   content = []\n",
    "   labels = []\n",
    "\n",
    "   for i in range(1,24):\n",
    "     p = 'C'+'%.2d' % i\n",
    "     file_path = os.path.join('ohsumed-all',str(p),'*')\n",
    "     for file in get_files_in_dir(file_path):\n",
    "        file_data = get_text_file_data(file)\n",
    "        content += [\"\".join(file_data)]\n",
    "        labels += [i]\n",
    "   features_train, features_test, labels_train, labels_test = train_test_split(content, labels, test_size=0.35, random_state=10)\n",
    "   \n",
    "   # ntc\n",
    "   vectorizer = TfidfVectorizer(use_idf=True, smooth_idf=False, max_df=0.5, stop_words='english')\n",
    "   features_train = vectorizer.fit_transform(features_train)\n",
    "   features_test = vectorizer.transform(features_test)\n",
    "\n",
    "   # Feature selection\n",
    "   selector = SelectPercentile(f_classif, percentile=5)\n",
    "   selector.fit(features_train, labels_train)\n",
    "   features_train = selector.transform(features_train)\n",
    "   features_test = selector.transform(features_test)\n",
    "   return features_train, features_test, labels_train, labels_test\n",
    "\n",
    "\n",
    "# MultinomialNB\n",
    "def multinomial_nb():\n",
    "   trg = test_training_data()\n",
    "   content_t = trg[0]\n",
    "   test_content = trg[1]\n",
    "   labels_t = trg[2]\n",
    "   test_labels = trg[3]\n",
    "\n",
    "   t0 = time()\n",
    "   naive_bayes_classifier = MultinomialNB()\n",
    "   naive_bayes_classifier.fit(content_t, labels_t)\n",
    "\n",
    "   training_time = time() - t0\n",
    "   print(\"train time: %0.3fs\" % training_time)\n",
    "   # print(f\"Training time: {round(time()-t0, 3)}s\")\n",
    "\n",
    "   t0 = time()\n",
    "   test_pred = naive_bayes_classifier.predict(test_content)\n",
    "   test_time = time() - t0\n",
    "   print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "\n",
    "   accuracy = metrics.accuracy_score(test_labels, test_pred)\n",
    "   print(\"accuracy:   %0.3f\" % accuracy)\n",
    "   # score_train = naive_bayes_classifier.score(content_t, labels_t)\n",
    "   # print(f\"Prediction time (train): {round(time()-t0, 3)}s\")\n",
    "\n",
    "   print(metrics.classification_report(test_labels, test_pred,\n",
    "       target_names = target_names))\n",
    "\n",
    "   print(micro_macro_average(test_labels,test_pred))\n",
    "\n",
    "   # print(\"confusion matrix:\")\n",
    "   # print(metrics.confusion_matrix(test_labels, test_pred))\n",
    "\n",
    "#BenoulliNB\n",
    "def bernoulli_nb():\n",
    "   trg = test_training_data()\n",
    "   content_t = trg[0]\n",
    "   test_content = trg[1]\n",
    "   labels_t = trg[2]\n",
    "   test_labels = trg[3]\n",
    "\n",
    "   t0 = time()\n",
    "   naive_bayes_classifier = BernoulliNB()\n",
    "   naive_bayes_classifier.fit(content_t, labels_t)\n",
    "\n",
    "   training_time = time() - t0\n",
    "   print(\"train time: %0.3fs\" % training_time)\n",
    "   # print(f\"Training time: {round(time()-t0, 3)}s\")\n",
    "\n",
    "   t0 = time()\n",
    "   test_pred = naive_bayes_classifier.predict(test_content)\n",
    "   test_time = time() - t0\n",
    "   print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "\n",
    "   accuracy = metrics.accuracy_score(test_labels, test_pred)\n",
    "   print(\"accuracy:   %0.3f\" % accuracy)\n",
    "   # score_train = naive_bayes_classifier.score(content_t, labels_t)\n",
    "   # print(f\"Prediction time (train): {round(time()-t0, 3)}s\")\n",
    "\n",
    "   print(metrics.classification_report(test_labels, test_pred,\n",
    "       target_names = target_names))\n",
    "\n",
    "   print(micro_macro_average(test_labels,test_pred))\n",
    "\n",
    "   # print(\"confusion matrix:\")\n",
    "   # print(metrics.confusion_matrix(test_labels, test_pred))\n",
    "\n",
    "#Knn with k=1\n",
    "def knn1_classifier():\n",
    "\n",
    "   trg = test_training_data()\n",
    "   content_t = trg[0]\n",
    "   test_content = trg[1]\n",
    "   labels_t = trg[2]\n",
    "   test_labels = trg[3]\n",
    "\n",
    "   t0 = time()\n",
    "   knn = KNeighborsClassifier(n_neighbors=1)\n",
    "   knn.fit(content_t, labels_t)\n",
    "\n",
    "   training_time = time() - t0\n",
    "   print(\"train time: %0.3fs\" % training_time)\n",
    "\n",
    "   t0 = time()\n",
    "   test_pred = knn.predict(test_content)\n",
    "   test_time = time() - t0\n",
    "   print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "\n",
    "   accuracy = metrics.accuracy_score(test_labels, test_pred)\n",
    "   print(\"accuracy:   %0.3f\" % accuracy)\n",
    "\n",
    "   print(metrics.classification_report(test_labels, test_pred,\n",
    "       target_names = target_names))\n",
    "\n",
    "   print(micro_macro_average(test_labels,test_pred))\n",
    "\n",
    "   # print(\"confusion matrix:\")\n",
    "   # print(metrics.confusion_matrix(test_labels, test_pred))\n",
    "\n",
    "\n",
    "#Knn with k=3\n",
    "def knn3_classifier():\n",
    "   trg = test_training_data()\n",
    "   content_t = trg[0]\n",
    "   test_content = trg[1]\n",
    "   labels_t = trg[2]\n",
    "   test_labels = trg[3]\n",
    "\n",
    "   t0 = time()\n",
    "   knn = KNeighborsClassifier(n_neighbors=3)\n",
    "   knn.fit(content_t, labels_t)\n",
    "\n",
    "   training_time = time() - t0\n",
    "   print(\"train time: %0.3fs\" % training_time)\n",
    "\n",
    "   t0 = time()\n",
    "   test_pred = knn.predict(test_content)\n",
    "   test_time = time() - t0\n",
    "   print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "\n",
    "   accuracy = metrics.accuracy_score(test_labels, test_pred)\n",
    "   print(\"accuracy:   %0.3f\" % accuracy)\n",
    "\n",
    "   print(metrics.classification_report(test_labels, test_pred,\n",
    "       target_names = target_names))\n",
    "\n",
    "   print(micro_macro_average(test_labels,test_pred))\n",
    "\n",
    "   # print(\"confusion matrix:\")\n",
    "   # print(metrics.confusion_matrix(test_labels, test_pred))\n",
    "\n",
    "\n",
    "#knn with k=5\n",
    "def knn5_classifier():\n",
    "   trg = test_training_data()\n",
    "   content_t = trg[0]\n",
    "   test_content = trg[1]\n",
    "   labels_t = trg[2]\n",
    "   test_labels = trg[3]\n",
    "\n",
    "   # k=5\n",
    "   t0 = time()\n",
    "   knn = KNeighborsClassifier(n_neighbors=5)\n",
    "   knn.fit(content_t, labels_t)\n",
    "\n",
    "   training_time = time() - t0\n",
    "   print(\"train time: %0.3fs\" % training_time)\n",
    "\n",
    "   t0 = time()\n",
    "   test_pred = knn.predict(test_content)\n",
    "   test_time = time() - t0\n",
    "   print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "\n",
    "   accuracy = metrics.accuracy_score(test_labels, test_pred)\n",
    "   print(\"accuracy:   %0.3f\" % accuracy)\n",
    "\n",
    "   print(metrics.classification_report(test_labels, test_pred,\n",
    "       target_names = target_names))\n",
    "\n",
    "   print(micro_macro_average(test_labels,test_pred))\n",
    "\n",
    "   # print(\"confusion matrix:\")\n",
    "   # print(metrics.confusion_matrix(test_labels, test_pred))\n",
    "\n",
    "\n",
    "#SVM with linear kernel\n",
    "def linear_svm():\n",
    "\n",
    "   trg = test_training_data()\n",
    "   content_t = trg[0]\n",
    "   test_content = trg[1]\n",
    "   labels_t = trg[2]\n",
    "   test_labels = trg[3]\n",
    "\n",
    "   t0 = time()\n",
    "   svc = svm.SVC(kernel ='linear', C = 1)\n",
    "   svc.fit(content_t, labels_t)\n",
    "\n",
    "   training_time = time() - t0\n",
    "   print(\"train time: %0.3fs\" % training_time)\n",
    "\n",
    "   t0 = time()\n",
    "   test_pred = svc.predict(test_content)\n",
    "   test_time = time() - t0\n",
    "   print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "\n",
    "   accuracy = metrics.accuracy_score(test_labels, test_pred)\n",
    "   print(\"accuracy:   %0.3f\" % accuracy)\n",
    "\n",
    "   print(metrics.classification_report(test_labels, test_pred,\n",
    "       target_names = target_names))\n",
    "\n",
    "   print(micro_macro_average(test_labels,test_pred))\n",
    "\n",
    "   # print(\"confusion matrix:\")\n",
    "   # print(metrics.confusion_matrix(test_labels, test_pred))\n",
    "\n",
    "\n",
    "# SVM with gaussian kernel\n",
    "def rbf_svm():\n",
    "\n",
    "   trg = test_training_data()\n",
    "   content_t = trg[0]\n",
    "   test_content = trg[1]\n",
    "   labels_t = trg[2]\n",
    "   test_labels = trg[3]\n",
    "\n",
    "   t0 = time()\n",
    "   svc = svm.SVC(kernel ='rbf', C = 0.4)\n",
    "   svc.fit(content_t, labels_t)\n",
    "\n",
    "   training_time = time() - t0\n",
    "   print(\"train time: %0.3fs\" % training_time)\n",
    "\n",
    "   t0 = time()\n",
    "   test_pred = svc.predict(test_content)\n",
    "   test_time = time() - t0\n",
    "   print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "\n",
    "   accuracy = metrics.accuracy_score(test_labels, test_pred)\n",
    "   print(\"accuracy:   %0.3f\" % accuracy)\n",
    "\n",
    "   print(metrics.classification_report(test_labels, test_pred,\n",
    "       target_names = target_names))\n",
    "\n",
    "   print(micro_macro_average(test_labels,test_pred))\n",
    "\n",
    "   # print(\"confusion matrix:\")\n",
    "   # print(metrics.confusion_matrix(test_labels, test_pred))\n",
    "\n",
    "\n",
    "\n",
    "#All needed functions:\n",
    "\n",
    "multinomial_nb()\n",
    "# bernoulli_nb()\n",
    "# knn1_classifier()\n",
    "# knn3_classifier()\n",
    "# knn5_classifier()\n",
    "# linear_svm()\n",
    "# rbf_svm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
